{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_rows = 1000\n",
    "pd.options.display.max_columns = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import database\n",
    "df = pd.read_csv('salary_data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns selection\n",
    "df_model = df[['avg_salary','Rating','Size','Type of ownership','Industry','Sector','Revenue','num_comp','hour','employer_provided',\n",
    "             'job_state','same_state','age','python','spark','aws','excel','job_simp','seniority','desc_len']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(742, 170)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a dummy of each column and catenate it\n",
    "df_dummies = pd.get_dummies(df_model,drop_first=True)\n",
    "df_dummies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the target and the rest of features\n",
    "features= df_dummies.drop('avg_salary', axis =1)\n",
    "target = df_dummies.avg_salary.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import split tool \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean absoluteerror for train max_depth 1 is: 27.66967265449559\n",
      "The mean absoluteerror for test max_depth 1 is: 30.196354540314275\n",
      "\n",
      "The mean absoluteerror for train max_depth 2 is: 25.4275132230183\n",
      "The mean absoluteerror for test max_depth 2 is: 27.60886868838114\n",
      "\n",
      "The mean absoluteerror for train max_depth 3 is: 23.851000024470647\n",
      "The mean absoluteerror for test max_depth 3 is: 25.600744509597735\n",
      "\n",
      "The mean absoluteerror for train max_depth 4 is: 21.383386913842795\n",
      "The mean absoluteerror for test max_depth 4 is: 23.705910023214475\n",
      "\n",
      "The mean absoluteerror for train max_depth 5 is: 19.399132541833417\n",
      "The mean absoluteerror for test max_depth 5 is: 21.871782573549343\n",
      "\n",
      "The mean absoluteerror for train max_depth 6 is: 16.97918721534741\n",
      "The mean absoluteerror for test max_depth 6 is: 18.932433160887577\n",
      "\n",
      "The mean absoluteerror for train max_depth 7 is: 14.34653858247407\n",
      "The mean absoluteerror for test max_depth 7 is: 17.915728750302023\n",
      "\n",
      "The mean absoluteerror for train max_depth 8 is: 11.834288568365153\n",
      "The mean absoluteerror for test max_depth 8 is: 16.057811117944922\n",
      "\n",
      "The mean absoluteerror for train max_depth 9 is: 9.88987424043041\n",
      "The mean absoluteerror for test max_depth 9 is: 14.831473471479116\n",
      "\n",
      "The mean absoluteerror for train max_depth 10 is: 7.839570120582033\n",
      "The mean absoluteerror for test max_depth 10 is: 13.111125724807039\n",
      "\n",
      "The mean absoluteerror for train max_depth 11 is: 5.869534978385844\n",
      "The mean absoluteerror for test max_depth 11 is: 12.930351643520318\n",
      "\n",
      "The mean absoluteerror for train max_depth 12 is: 4.165369313092754\n",
      "The mean absoluteerror for test max_depth 12 is: 11.68652929844205\n",
      "\n",
      "The mean absoluteerror for train max_depth 13 is: 3.171521115956192\n",
      "The mean absoluteerror for test max_depth 13 is: 11.174017546584661\n",
      "\n",
      "The mean absoluteerror for train max_depth 14 is: 2.252103424025852\n",
      "The mean absoluteerror for test max_depth 14 is: 11.08640406945776\n",
      "\n",
      "The mean absoluteerror for train max_depth 15 is: 1.5320640240948897\n",
      "The mean absoluteerror for test max_depth 15 is: 10.241469445425643\n",
      "\n",
      "The mean absoluteerror for train max_depth 16 is: 1.1276312267458979\n",
      "The mean absoluteerror for test max_depth 16 is: 9.668056887184404\n",
      "\n",
      "The mean absoluteerror for train max_depth 17 is: 0.8362041736700107\n",
      "The mean absoluteerror for test max_depth 17 is: 9.513454961557253\n",
      "\n",
      "The mean absoluteerror for train max_depth 18 is: 0.6325182686902755\n",
      "The mean absoluteerror for test max_depth 18 is: 8.55791171915333\n",
      "\n",
      "The mean absoluteerror for train max_depth 19 is: 0.3916385609893199\n",
      "The mean absoluteerror for test max_depth 19 is: 9.669826621923937\n",
      "\n",
      "The mean absoluteerror for train max_depth 20 is: 0.25054203806311737\n",
      "The mean absoluteerror for test max_depth 20 is: 10.19658836689038\n",
      "\n",
      "The mean absoluteerror for train max_depth 21 is: 0.13415283571491968\n",
      "The mean absoluteerror for test max_depth 21 is: 10.03020134228188\n",
      "\n",
      "The mean absoluteerror for train max_depth 22 is: 0.11313361769665709\n",
      "The mean absoluteerror for test max_depth 22 is: 9.507303592577971\n",
      "\n",
      "The mean absoluteerror for train max_depth 23 is: 0.08768971332209106\n",
      "The mean absoluteerror for test max_depth 23 is: 9.126677852348994\n",
      "\n",
      "The mean absoluteerror for train max_depth 24 is: 0.07419898819561552\n",
      "The mean absoluteerror for test max_depth 24 is: 9.75503355704698\n",
      "\n",
      "The mean absoluteerror for train max_depth 25 is: 0.04384485666104553\n",
      "The mean absoluteerror for test max_depth 25 is: 8.333333333333334\n",
      "\n",
      "The mean absoluteerror for train max_depth 26 is: 0.02065767284991568\n",
      "The mean absoluteerror for test max_depth 26 is: 9.50251677852349\n",
      "\n",
      "The mean absoluteerror for train max_depth 27 is: 0.007869589657110744\n",
      "The mean absoluteerror for test max_depth 27 is: 8.838926174496644\n",
      "\n",
      "The mean absoluteerror for train max_depth 28 is: 0.0022484541877459286\n",
      "The mean absoluteerror for test max_depth 28 is: 9.440715883668902\n",
      "\n",
      "The mean absoluteerror for train max_depth 29 is: 0.0\n",
      "The mean absoluteerror for test max_depth 29 is: 10.171140939597315\n",
      "\n",
      "The mean absoluteerror for train max_depth 30 is: 0.0\n",
      "The mean absoluteerror for test max_depth 30 is: 10.171140939597315\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import Decision Tree Regressor model\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Import mean absolute error metric\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "for i in range(1,31):\n",
    "    regressor = DecisionTreeRegressor(max_depth=i, random_state=42)\n",
    "    regressor.fit(X_train, y_train)\n",
    "    train_predict = regressor.predict(X_train)\n",
    "    print('The mean absoluteerror for train max_depth {} is:'.format(i), mean_absolute_error(y_train,train_predict))\n",
    "    test_predict = regressor.predict(X_test)\n",
    "    print('The mean absoluteerror for test max_depth {} is:'.format(i), mean_absolute_error(y_test,test_predict))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean absoluteerror for train min_samples_leaf 1 is: 0.04384485666104553\n",
      "The mean absoluteerror for test min_samples_leaf 1 is: 8.333333333333334\n",
      "\n",
      "The mean absoluteerror for train min_samples_leaf 3 is: 7.3267847105115225\n",
      "The mean absoluteerror for test min_samples_leaf 3 is: 14.463199105145412\n",
      "\n",
      "The mean absoluteerror for train min_samples_leaf 5 is: 12.23715235953853\n",
      "The mean absoluteerror for test min_samples_leaf 5 is: 17.53412432086929\n",
      "\n",
      "The mean absoluteerror for train min_samples_leaf 7 is: 14.55768427281918\n",
      "The mean absoluteerror for test min_samples_leaf 7 is: 19.477916006439496\n",
      "\n",
      "The mean absoluteerror for train min_samples_leaf 9 is: 16.11203885074905\n",
      "The mean absoluteerror for test min_samples_leaf 9 is: 19.850721476619626\n",
      "\n",
      "The mean absoluteerror for train min_samples_leaf 11 is: 17.063480984278385\n",
      "The mean absoluteerror for test min_samples_leaf 11 is: 21.42770989543929\n",
      "\n",
      "The mean absoluteerror for train min_samples_leaf 13 is: 17.675419184800823\n",
      "The mean absoluteerror for test min_samples_leaf 13 is: 21.62321207519137\n",
      "\n",
      "The mean absoluteerror for train min_samples_leaf 15 is: 17.86974494840649\n",
      "The mean absoluteerror for test min_samples_leaf 15 is: 21.570156388613007\n",
      "\n",
      "The mean absoluteerror for train min_samples_leaf 17 is: 18.723893033183156\n",
      "The mean absoluteerror for test min_samples_leaf 17 is: 22.551800582705432\n",
      "\n",
      "The mean absoluteerror for train min_samples_leaf 19 is: 18.91843923657983\n",
      "The mean absoluteerror for test min_samples_leaf 19 is: 23.527137590123434\n",
      "\n",
      "The mean absoluteerror for train min_samples_leaf 21 is: 19.685369340022262\n",
      "The mean absoluteerror for test min_samples_leaf 21 is: 23.693147180538247\n",
      "\n",
      "The mean absoluteerror for train min_samples_leaf 23 is: 21.09407063241241\n",
      "The mean absoluteerror for test min_samples_leaf 23 is: 23.977524913564583\n",
      "\n",
      "The mean absoluteerror for train min_samples_leaf 25 is: 21.27010475535035\n",
      "The mean absoluteerror for test min_samples_leaf 25 is: 23.398225451065645\n",
      "\n",
      "The mean absoluteerror for train min_samples_leaf 27 is: 21.560613857170093\n",
      "The mean absoluteerror for test min_samples_leaf 27 is: 23.47357306099664\n",
      "\n",
      "The mean absoluteerror for train min_samples_leaf 29 is: 22.490031096725\n",
      "The mean absoluteerror for test min_samples_leaf 29 is: 24.721996006014432\n",
      "\n",
      "The mean absoluteerror for train min_samples_leaf 31 is: 22.638824432184617\n",
      "The mean absoluteerror for test min_samples_leaf 31 is: 24.58927022938678\n",
      "\n",
      "The mean absoluteerror for train min_samples_leaf 33 is: 22.825708392951654\n",
      "The mean absoluteerror for test min_samples_leaf 33 is: 25.26954134922363\n",
      "\n",
      "The mean absoluteerror for train min_samples_leaf 35 is: 23.024246257436808\n",
      "The mean absoluteerror for test min_samples_leaf 35 is: 26.035634895916854\n",
      "\n",
      "The mean absoluteerror for train min_samples_leaf 37 is: 23.09692841524771\n",
      "The mean absoluteerror for test min_samples_leaf 37 is: 26.46983542159031\n",
      "\n",
      "The mean absoluteerror for train min_samples_leaf 39 is: 23.06941443637135\n",
      "The mean absoluteerror for test min_samples_leaf 39 is: 26.51010387796615\n",
      "\n",
      "The mean absoluteerror for train min_samples_leaf 41 is: 23.197920762204987\n",
      "The mean absoluteerror for test min_samples_leaf 41 is: 27.03911973888476\n",
      "\n",
      "The mean absoluteerror for train min_samples_leaf 43 is: 23.265815976327794\n",
      "The mean absoluteerror for test min_samples_leaf 43 is: 26.848711863733133\n",
      "\n",
      "The mean absoluteerror for train min_samples_leaf 45 is: 23.30673285987329\n",
      "The mean absoluteerror for test min_samples_leaf 45 is: 26.838710037153056\n",
      "\n",
      "The mean absoluteerror for train min_samples_leaf 47 is: 23.466881201507018\n",
      "The mean absoluteerror for test min_samples_leaf 47 is: 26.68358241179927\n",
      "\n",
      "The mean absoluteerror for train min_samples_leaf 49 is: 23.70566116052238\n",
      "The mean absoluteerror for test min_samples_leaf 49 is: 26.540501447048385\n",
      "\n",
      "The mean absoluteerror for train min_samples_leaf 51 is: 23.92585785115663\n",
      "The mean absoluteerror for test min_samples_leaf 51 is: 26.70935239017665\n",
      "\n",
      "The mean absoluteerror for train min_samples_leaf 53 is: 23.978709020027225\n",
      "The mean absoluteerror for test min_samples_leaf 53 is: 26.681507616551865\n",
      "\n",
      "The mean absoluteerror for train min_samples_leaf 55 is: 24.107641072875087\n",
      "The mean absoluteerror for test min_samples_leaf 55 is: 26.390768235844774\n",
      "\n",
      "The mean absoluteerror for train min_samples_leaf 57 is: 24.137266223547208\n",
      "The mean absoluteerror for test min_samples_leaf 57 is: 26.271931625373067\n",
      "\n",
      "The mean absoluteerror for train min_samples_leaf 59 is: 24.14740755070039\n",
      "The mean absoluteerror for test min_samples_leaf 59 is: 26.255186255423872\n",
      "\n",
      "The mean absoluteerror for train min_samples_leaf 61 is: 24.14740755070039\n",
      "The mean absoluteerror for test min_samples_leaf 61 is: 26.255186255423872\n",
      "\n",
      "The mean absoluteerror for train min_samples_leaf 63 is: 24.166895316643103\n",
      "The mean absoluteerror for test min_samples_leaf 63 is: 26.2531367274079\n",
      "\n",
      "The mean absoluteerror for train min_samples_leaf 65 is: 24.20839289838214\n",
      "The mean absoluteerror for test min_samples_leaf 65 is: 26.462354542956476\n",
      "\n",
      "The mean absoluteerror for train min_samples_leaf 67 is: 24.20839289838214\n",
      "The mean absoluteerror for test min_samples_leaf 67 is: 26.462354542956476\n",
      "\n",
      "The mean absoluteerror for train min_samples_leaf 69 is: 24.24676440497274\n",
      "The mean absoluteerror for test min_samples_leaf 69 is: 26.444906916163585\n",
      "\n",
      "The mean absoluteerror for train min_samples_leaf 71 is: 24.24676440497274\n",
      "The mean absoluteerror for test min_samples_leaf 71 is: 26.444906916163585\n",
      "\n",
      "The mean absoluteerror for train min_samples_leaf 73 is: 24.33525873346071\n",
      "The mean absoluteerror for test min_samples_leaf 73 is: 26.5249310528935\n",
      "\n",
      "The mean absoluteerror for train min_samples_leaf 75 is: 24.389934094580536\n",
      "The mean absoluteerror for test min_samples_leaf 75 is: 26.578606024996894\n",
      "\n",
      "The mean absoluteerror for train min_samples_leaf 77 is: 25.263164503997487\n",
      "The mean absoluteerror for test min_samples_leaf 77 is: 28.1060206088976\n",
      "\n",
      "The mean absoluteerror for train min_samples_leaf 79 is: 25.263164503997487\n",
      "The mean absoluteerror for test min_samples_leaf 79 is: 28.1060206088976\n",
      "\n",
      "The mean absoluteerror for train min_samples_leaf 81 is: 25.263164503997487\n",
      "The mean absoluteerror for test min_samples_leaf 81 is: 28.1060206088976\n",
      "\n",
      "The mean absoluteerror for train min_samples_leaf 83 is: 25.263164503997487\n",
      "The mean absoluteerror for test min_samples_leaf 83 is: 28.1060206088976\n",
      "\n",
      "The mean absoluteerror for train min_samples_leaf 85 is: 25.263164503997487\n",
      "The mean absoluteerror for test min_samples_leaf 85 is: 28.1060206088976\n",
      "\n",
      "The mean absoluteerror for train min_samples_leaf 87 is: 25.306350500040207\n",
      "The mean absoluteerror for test min_samples_leaf 87 is: 28.088753147483157\n",
      "\n",
      "The mean absoluteerror for train min_samples_leaf 89 is: 25.340925821073675\n",
      "The mean absoluteerror for test min_samples_leaf 89 is: 28.073186784071197\n",
      "\n",
      "The mean absoluteerror for train min_samples_leaf 91 is: 25.5027970977069\n",
      "The mean absoluteerror for test min_samples_leaf 91 is: 27.97632030941277\n",
      "\n",
      "The mean absoluteerror for train min_samples_leaf 93 is: 25.9008017180416\n",
      "The mean absoluteerror for test min_samples_leaf 93 is: 28.742118851473222\n",
      "\n",
      "The mean absoluteerror for train min_samples_leaf 95 is: 25.94988570235415\n",
      "The mean absoluteerror for test min_samples_leaf 95 is: 28.737302063334113\n",
      "\n",
      "The mean absoluteerror for train min_samples_leaf 97 is: 26.169477039572087\n",
      "The mean absoluteerror for test min_samples_leaf 97 is: 28.23362837472078\n",
      "\n",
      "The mean absoluteerror for train min_samples_leaf 99 is: 26.169477039572087\n",
      "The mean absoluteerror for test min_samples_leaf 99 is: 28.23362837472078\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,100,2):\n",
    "    regressor = DecisionTreeRegressor(max_depth=25, min_samples_leaf=i, random_state=42)\n",
    "    regressor.fit(X_train, y_train)\n",
    "    train_predict = regressor.predict(X_train)\n",
    "    print('The mean absoluteerror for train min_samples_leaf {} is:'.format(i), mean_absolute_error(y_train,train_predict))\n",
    "    test_predict = regressor.predict(X_test)\n",
    "    print('The mean absoluteerror for test min_samples_leaf {} is:'.format(i), mean_absolute_error(y_test,test_predict))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 10, 'min_samples_leaf': 5}\n",
      "DecisionTreeRegressor(criterion='mse', max_depth=10, max_features=None,\n",
      "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=5,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      presort=False, random_state=42, splitter='best')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:    3.9s finished\n",
      "/Users/haithamqutaiba/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "DTR = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "params = {\n",
    "    'max_depth': [2, 3, 5, 10, 20, 25],\n",
    "    'min_samples_leaf': [5, 10, 20, 50, 100]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=DTR, \n",
    "                           param_grid=params, \n",
    "                           cv=3, n_jobs=-1, verbose=1, scoring='neg_mean_absolute_error')\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "# print best parameter after tuning\n",
    "print(grid_search.best_params_)\n",
    " \n",
    "# print how our model looks after hyper-parameter tuning\n",
    "print(grid_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.088465281921657\n"
     ]
    }
   ],
   "source": [
    "test_grid_predictions = grid_search.predict(X_test)\n",
    "test_grid_mae = mean_absolute_error(y_test, test_grid_predictions)\n",
    "print(test_grid_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.728187919463087\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# random forest for making predictions for regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# define the model\n",
    "RFR = RandomForestRegressor()\n",
    "# fit the model on the whole dataset\n",
    "RFR.fit(X_train, y_train)\n",
    "\n",
    "# make prediction\n",
    "\n",
    "test_predictions = RFR.predict(X_test)\n",
    "test_mae = mean_absolute_error(y_test, test_predictions)\n",
    "print(test_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning the Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = np.linspace(100, 500, 50, dtype=int) \n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [1, 5, 10, 20]\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [0.2, 0.4, 0.6]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 3, 4]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "param_grid = {'n_estimators': n_estimators,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4800 candidates, totalling 14400 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=-1)]: Done 280 tasks      | elapsed:   43.1s\n",
      "[Parallel(n_jobs=-1)]: Done 504 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1144 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1560 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2040 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2584 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3192 tasks      | elapsed: 10.8min\n",
      "[Parallel(n_jobs=-1)]: Done 3864 tasks      | elapsed: 13.6min\n",
      "[Parallel(n_jobs=-1)]: Done 4600 tasks      | elapsed: 16.5min\n",
      "[Parallel(n_jobs=-1)]: Done 5400 tasks      | elapsed: 19.7min\n",
      "[Parallel(n_jobs=-1)]: Done 6264 tasks      | elapsed: 23.8min\n",
      "[Parallel(n_jobs=-1)]: Done 7192 tasks      | elapsed: 28.7min\n",
      "[Parallel(n_jobs=-1)]: Done 8184 tasks      | elapsed: 32.9min\n",
      "[Parallel(n_jobs=-1)]: Done 9240 tasks      | elapsed: 186.3min\n",
      "[Parallel(n_jobs=-1)]: Done 10360 tasks      | elapsed: 191.7min\n",
      "[Parallel(n_jobs=-1)]: Done 11544 tasks      | elapsed: 198.1min\n",
      "[Parallel(n_jobs=-1)]: Done 12792 tasks      | elapsed: 204.5min\n",
      "[Parallel(n_jobs=-1)]: Done 14104 tasks      | elapsed: 218.1min\n",
      "[Parallel(n_jobs=-1)]: Done 14400 out of 14400 | elapsed: 219.3min finished\n",
      "/Users/haithamqutaiba/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=RandomForestRegressor(bootstrap=True, criterion='mse',\n",
       "                                             max_depth=None,\n",
       "                                             max_features='auto',\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             n_estimators='warn', n_jobs=None,\n",
       "                                             oob_score=False, random_stat...\n",
       "                         'min_samples_split': [0.2, 0.4, 0.6],\n",
       "                         'n_estimators': array([100, 108, 116, 124, 132, 140, 148, 157, 165, 173, 181, 189, 197,\n",
       "       206, 214, 222, 230, 238, 246, 255, 263, 271, 279, 287, 295, 304,\n",
       "       312, 320, 328, 336, 344, 353, 361, 369, 377, 385, 393, 402, 410,\n",
       "       418, 426, 434, 442, 451, 459, 467, 475, 483, 491, 500])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_absolute_error', verbose=3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rfr_base = RandomForestRegressor()\n",
    "\n",
    "grid = GridSearchCV(rfr_base, param_grid, refit = True, verbose = 3, \n",
    "                    scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    " \n",
    "# fitting the model for grid search\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': False, 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 0.2, 'n_estimators': 483}\n",
      "RandomForestRegressor(bootstrap=False, criterion='mse', max_depth=10,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=2, min_samples_split=0.2,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators=483,\n",
      "                      n_jobs=None, oob_score=False, random_state=None,\n",
      "                      verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# print best parameter after tuning\n",
    "print(grid.best_params_)\n",
    " \n",
    "# print how our model looks after hyper-parameter tuning\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.088465281921657\n"
     ]
    }
   ],
   "source": [
    "predictions = grid.predict(X_test)\n",
    "test_mae = mean_absolute_error(y_test, predictions)\n",
    "print(test_grid_mae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
